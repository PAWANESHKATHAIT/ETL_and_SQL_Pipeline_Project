{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf881033-5242-4fa1-8666-bfa7ea8551ad",
   "metadata": {},
   "source": [
    "### Python Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432cf299-61c4-44d7-a90b-f329a57b1f28",
   "metadata": {},
   "source": [
    "#### ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f3a84e-0a78-46ea-b876-3182b84f42f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd8de2d7-0811-4b8c-8c7e-e36e2258d26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract\n",
    "df = pd.read_csv('product_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ec5a5e-24b9-4056-bed2-e6c986643302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Transform\n",
    "# Remove rows with null rating or review_text\n",
    "df = df.dropna(subset=['rating', 'review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "210c4083-5dca-498c-820e-c281fdf872fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rating to integer and filter out invalid ratings\n",
    "df['rating'] = df['rating'].astype(int)\n",
    "df = df[(df['rating'] >= 1) & (df['rating'] <= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b191d5c3-34be-4f05-a45c-9a5c5bc14606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment extraction logic\n",
    "df['sentiment'] = df['review_text'].apply(lambda x: 'Negative' if 'bad' in x.lower() else 'Positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa784a7-e5b1-4d2b-b553-7f78bc4cfec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load\n",
    "df.to_csv('cleaned_product_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9228ed0-2558-430b-9af2-0c065d2240a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8eccd4d7-f294-42b2-865e-0ee34e5783f6",
   "metadata": {},
   "source": [
    "#### Data Deduplication (Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1303d2e-f7d7-4d44-9f8c-fab6ea642cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the file\n",
    "df = pd.read_csv('user_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d77e05a-dd27-409d-a2d4-1af4b2c14398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Deduplication\n",
    "df['last_updated'] = pd.to_datetime(df['last_updated'])  # Ensure 'last_updated' is in datetime format\n",
    "df = df.sort_values('last_updated', ascending=False)  # Sort by most recent update\n",
    "df = df.drop_duplicates(subset='email', keep='first')  # Drop duplicates, keeping the most recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a9f61f2-7e5b-46fa-a109-d13404bedd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Output the cleaned file\n",
    "df.to_csv('cleaned_user_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac09c77-bc65-4929-b3a9-15fab38924de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "335fa528-53f0-4d64-aac6-2d71ebe0cb77",
   "metadata": {},
   "source": [
    "### SQL Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68655f9c-ab51-4c9b-8721-2f35845bf372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Connect to an in-memory SQLite database (for temporary work)\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "771686ee-70f0-437d-a370-20a8946761ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: creating users and orders\n",
    "users_df = pd.DataFrame({\n",
    "    'user_id': ['U1', 'U2', 'U3'],\n",
    "    'name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'signup_date': ['2023-01-01', '2023-02-01', '2023-03-01']\n",
    "})\n",
    "\n",
    "orders_df = pd.DataFrame({\n",
    "    'order_id': ['O1', 'O2', 'O3', 'O4', 'O5', 'O6'],\n",
    "    'user_id': ['U1', 'U1', 'U1', 'U1', 'U2', 'U3'],\n",
    "    'amount': [100, 150, 200, 50, 80, 40],\n",
    "    'order_date': ['2025-02-01', '2025-02-15', '2025-03-01', '2025-04-01', '2025-01-15', '2025-04-01']\n",
    "})\n",
    "\n",
    "users_df.to_sql('users', conn, index=False, if_exists='replace')\n",
    "orders_df.to_sql('orders', conn, index=False, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d874d0-e334-41d1-9965-69e3d57a68e8",
   "metadata": {},
   "source": [
    "#### 1. Users with >3 orders in last 90 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d13ff5a4-9e5c-479a-b1b6-e2683c447406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  user_id   name  order_count  total_spent\n",
      "0      U1  Alice            4          500\n"
     ]
    }
   ],
   "source": [
    "query1 = '''\n",
    "SELECT \n",
    "    u.user_id,\n",
    "    u.name,\n",
    "    COUNT(o.order_id) AS order_count,\n",
    "    SUM(o.amount) AS total_spent\n",
    "FROM \n",
    "    users u\n",
    "JOIN \n",
    "    orders o ON u.user_id = o.user_id\n",
    "WHERE \n",
    "    o.order_date >= DATE('now', '-90 day')\n",
    "GROUP BY \n",
    "    u.user_id, u.name\n",
    "HAVING \n",
    "    COUNT(o.order_id) > 3;\n",
    "'''\n",
    "\n",
    "df_result1 = pd.read_sql_query(query1, conn)\n",
    "print(df_result1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4f0579-6ce3-4e71-8a0c-104bfec08fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd228bc3-b2a8-4bcb-8446-495219635129",
   "metadata": {},
   "source": [
    "### Missing Hourly Sensor Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29b7ff2b-29b3-4cdd-be38-59d80408ab8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sensor_id        expected_time\n",
      "0         S1  2025-04-11 10:20:55\n",
      "1         S1  2025-04-11 11:20:55\n",
      "2         S1  2025-04-11 12:20:55\n",
      "3         S1  2025-04-11 13:20:55\n",
      "4         S1  2025-04-11 14:20:55\n",
      "5         S1  2025-04-11 15:20:55\n",
      "6         S1  2025-04-11 16:20:55\n",
      "7         S2  2025-04-11 10:20:55\n",
      "8         S2  2025-04-11 11:20:55\n",
      "9         S2  2025-04-11 12:20:55\n",
      "10        S2  2025-04-11 13:20:55\n",
      "11        S2  2025-04-11 14:20:55\n",
      "12        S2  2025-04-11 15:20:55\n"
     ]
    }
   ],
   "source": [
    "# Sample data first\n",
    "sensor_df = pd.DataFrame({\n",
    "    'sensor_id': ['S1'] * 23 + ['S2'] * 24,\n",
    "    'timestamp': pd.date_range(end=pd.Timestamp.now(), periods=23, freq='H').tolist() +\n",
    "                 pd.date_range(end=pd.Timestamp.now(), periods=24, freq='H').tolist(),\n",
    "    'reading': [42]*47\n",
    "})\n",
    "sensor_df.to_sql('sensor_logs', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Run the missing data query\n",
    "query2 = '''\n",
    "WITH hours AS (\n",
    "    SELECT DATETIME(DATETIME('now', '-1 day'), '+' || n || ' hours') AS expected_time\n",
    "    FROM (\n",
    "        SELECT 0 AS n UNION ALL SELECT 1 UNION ALL SELECT 2 UNION ALL SELECT 3 UNION ALL SELECT 4\n",
    "        UNION ALL SELECT 5 UNION ALL SELECT 6 UNION ALL SELECT 7 UNION ALL SELECT 8 UNION ALL SELECT 9\n",
    "        UNION ALL SELECT 10 UNION ALL SELECT 11 UNION ALL SELECT 12 UNION ALL SELECT 13 UNION ALL SELECT 14\n",
    "        UNION ALL SELECT 15 UNION ALL SELECT 16 UNION ALL SELECT 17 UNION ALL SELECT 18 UNION ALL SELECT 19\n",
    "        UNION ALL SELECT 20 UNION ALL SELECT 21 UNION ALL SELECT 22 UNION ALL SELECT 23\n",
    "    )\n",
    "),\n",
    "sensors AS (\n",
    "    SELECT DISTINCT sensor_id FROM sensor_logs\n",
    "),\n",
    "expected_logs AS (\n",
    "    SELECT \n",
    "        s.sensor_id, \n",
    "        h.expected_time\n",
    "    FROM \n",
    "        sensors s\n",
    "    CROSS JOIN \n",
    "        hours h\n",
    ")\n",
    "SELECT \n",
    "    e.sensor_id, \n",
    "    e.expected_time\n",
    "FROM \n",
    "    expected_logs e\n",
    "LEFT JOIN \n",
    "    sensor_logs sl \n",
    "    ON e.sensor_id = sl.sensor_id \n",
    "    AND strftime('%Y-%m-%d %H', sl.timestamp) = strftime('%Y-%m-%d %H', e.expected_time)\n",
    "WHERE \n",
    "    sl.timestamp IS NULL\n",
    "ORDER BY \n",
    "    e.sensor_id, e.expected_time;\n",
    "'''\n",
    "\n",
    "df_result2 = pd.read_sql_query(query2, conn)\n",
    "print(df_result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a23cd-9f82-406c-8c1d-9aa058c4608b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79f97647-ff23-4b5b-99fa-173f3b104ea2",
   "metadata": {},
   "source": [
    "###  VIP Gold Customers (Purchases + Membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9f4750c-9258-4922-ada6-3ad446d326d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_id  total_spent membership_level\n",
      "0        C001        420.5             Gold\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "purchases_df = pd.DataFrame({\n",
    "    'transaction_id': ['T1001', 'T1002', 'T1003', 'T1004'],\n",
    "    'customer_id': ['C001', 'C002', 'C001', 'C003'],\n",
    "    'amount': [120.50, 200.00, 300.00, 50.00],\n",
    "    'transaction_date': ['2024-03-15', '2024-03-15', '2024-03-16', '2024-03-17']\n",
    "})\n",
    "\n",
    "members_df = pd.DataFrame({\n",
    "    'customer_id': ['C001', 'C002', 'C004'],\n",
    "    'member_since': ['2023-05-01', '2023-11-15', '2024-01-10'],\n",
    "    'membership_level': ['Gold', 'Silver', 'Gold']\n",
    "})\n",
    "\n",
    "purchases_df.to_sql('purchases', conn, index=False, if_exists='replace')\n",
    "members_df.to_sql('members', conn, index=False, if_exists='replace')\n",
    "\n",
    "query3 = '''\n",
    "SELECT \n",
    "    m.customer_id,\n",
    "    SUM(p.amount) AS total_spent,\n",
    "    m.membership_level\n",
    "FROM \n",
    "    purchases p\n",
    "INNER JOIN \n",
    "    members m ON p.customer_id = m.customer_id\n",
    "WHERE \n",
    "    m.membership_level = 'Gold'\n",
    "GROUP BY \n",
    "    m.customer_id, m.membership_level\n",
    "HAVING \n",
    "    total_spent > 250;\n",
    "'''\n",
    "\n",
    "df_result3 = pd.read_sql_query(query3, conn)\n",
    "print(df_result3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5abe8f0-be4e-481e-95aa-7bffd95540b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
